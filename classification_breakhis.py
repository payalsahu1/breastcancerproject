# -*- coding: utf-8 -*-
"""Classification BreaKHis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17bS5laCUcRkQ16700ilCGJy4gH7koHPA

# Introduction

In this colab file, we have built a classification model for Breast Cancer into benign and malignant categories using VGG16 as our classifier.
First, we start by installing tensorflow and importing the necessary packages and libraries.
"""

!pip install tensorflow

!pip install visualkeras

#importing necessary packages
import os
import tensorflow as tf
import numpy as np
import cv2
from tensorflow import keras
import matplotlib.pyplot as plt
import shutil
import hashlib
from hashlib import md5
import imageio.v2 as imageio
from imageio import imread
import pandas as pd
from keras.utils import img_to_array, array_to_img
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

from sklearn.metrics import classification_report, accuracy_score
from keras.applications.vgg16 import VGG16
+from keras.applications.vgg16 import preprocess_input
import visualkeras

#setting gpu memory consumption growth
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu, True)

#downloading kaggle.json file
!gdown "https://drive.google.com/uc?id=1UvRuiTaifBWLHnueH8z4Bj5gihcaxmiM"

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!chmod 600 /root/.kaggle/kaggle.json

#downloading dataset from kaggle
!kaggle datasets download -d forderation/breakhis-400x

#unzipping
!unzip breakhis-400x.zip

"""# Exploratory Data Analysis

In this section, we will explore our image dataset by looking at the different classes we have, the total number of images and finding duplicated images in the dataset.
"""

#function to move images from the folders

def move_images(datadir, dest):
  for imgs in os.listdir(datadir):
    source = (os.path.join(datadir, imgs))
    shutil.move(source,dest)

move_images("/content/BreaKHis 400X/test/benign", "/content/BreaKHis 400X/train/benign")
move_images("/content/BreaKHis 400X/test/malignant", "/content/BreaKHis 400X/train/malignant")

data_dir = "/content/BreaKHis 400X/train"

print("The two classes inside this dataset are: ")
for image_class in os.listdir(data_dir):
  print(image_class)

plt.figure(figsize=(16,8))
plt.subplot(141)
image1 =cv2.imread("/content/BreaKHis 400X/train/benign/SOB_B_A-14-22549AB-400-001.png")
plt.imshow(image1)
plt.title("Benign")
plt.xticks([])
plt.yticks([])
plt.subplot(142)
image2 = cv2.imread("/content/BreaKHis 400X/train/malignant/SOB_M_DC-14-10926-400-002.png")
plt.imshow(image2)
plt.title("Malignant")
plt.xticks([])
plt.yticks([])
plt.subplot(143)
image3 = cv2.imread("/content/BreaKHis 400X/train/benign/SOB_B_A-14-22549AB-400-002.png")
plt.imshow(image3)
plt.title("Benign")
plt.xticks([])
plt.yticks([])
plt.subplot(144)
image4 = cv2.imread("/content/BreaKHis 400X/train/malignant/SOB_M_DC-14-10926-400-003.png")
plt.imshow(image4)
plt.title("Malignant")
plt.xticks([])
plt.yticks([])
plt.show()

malignant_dir = "/content/BreaKHis 400X/train/malignant"
benign_dir = "/content/BreaKHis 400X/train/benign"

#the number of images inside the folders

m_count = len(os.listdir(malignant_dir))
b_count = len(os.listdir(benign_dir))
print("The total number of benign images: " + str(b_count))
print ("The total number of malignant images: " + str(m_count))

#showing a visual representation
x_axis = ['Malignant', 'Benign']
y_axis = [int(m_count), int(b_count)]

fig = plt.figure(figsize=(10, 4))
plt.bar(x_axis, y_axis, color='pink')
plt.title('Number of images for each class')
plt.xlabel('Types of pcos classes', fontsize=12)
plt.ylabel('No. of Images', fontsize=12)
plt.show()

"""We've created a function to find the hash value of an image using the md5 algorithm. Duplicates can lead to biases during training therefore, it is important to remove them. We do this by saving the index of every unique hash value in a dictionary and when found to be repeated they get appended in a list with the index of the orignal hash value."""

#function to give the hash value of an image
def image_hash(imagepath):
  with open(imagepath, 'rb') as f:
    return md5(f.read()).hexdigest()

#function to find duplicates of an image by its hash value

def find_duplicates(dir_name):
  #empty list to store index of duplicate images
  duplicates =[]

  #empty dictionary to save index of non duplicated images
  hash_keys = {}

  for index, imgfile in enumerate(os.listdir(dir_name)):
    imagepath = (os.path.join(dir_name, imgfile))
    filehash = image_hash(imagepath)
    if filehash not in hash_keys:
      hash_keys[filehash] = index
    else:
      #if same hash value is found it is added in the list
      duplicates.append((index, hash_keys[filehash]))

  return duplicates

m_duplicates = find_duplicates(malignant_dir)
print(m_duplicates)
print()
print("The total number of duplicate images for Malignant Cancer are: " + str(len(m_duplicates)))

b_duplicates = find_duplicates(benign_dir)
print(b_duplicates)
print()
print("The total number of duplicate images for Benign Cancer are: " + str(len(b_duplicates)))

os.chdir("/content/")

"""# Pre-processing

Here, we resize the images and save the as numpy arrays.
"""

def preprocessing(dir_name):

  labels = {}
  preprocessed_labels = []
  preprocessed_image = []
  i = 0

  for image_class in os.listdir(dir_name):
    labels[i] = image_class
    for img in os.listdir(os.path.join(dir_name, image_class)):
      path = os.path.join(dir_name, image_class, img)

      image = cv2.imread(path)
      image = cv2.resize(image, (224, 224))

      preprocessed_image.append(image)
      preprocessed_labels.append(i)

    i+=1

  preprocessed_image = np.array(preprocessed_image)
  preprocessed_labels = np.array(preprocessed_labels)
  print("Preprocessing is complete!")
  return preprocessed_image, preprocessed_labels, labels

#applying the preprocessing function on our data directory and then saving them
x, y, labels = preprocessing(data_dir)

labels

"""# Train-Test Split

We've split the data into a ratio of 80:20 for training and testing respectively. Separate folders for train and test are created and images are divided following the above mentioned ratio.
"""

#splitting our preprocessed images in 80:20 for training and testing respectively
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Commented out IPython magic to ensure Python compatibility.
#making train and test folders

!apt-get install tree

# %mkdir train test train/benign train/malignant test/benign test/malignant
!tree -d

train_dir = "/content/train"
test_dir = "/content/test"

#function to save images to directory

def save_images(x_set, y_set, dir):
  i = 0
  for (img, imgclass) in zip(x_set, y_set):
    if imgclass == 0:
      cv2.imwrite(os.path.join(dir, 'benign', str(i) + '.jpg' ), img)
    else:
      cv2.imwrite(os.path.join(dir, 'malignant', str(i) + '.jpg'), img)
    i+=1
  print("Images successfully saved!")

save_images(x_train, y_train, train_dir)
save_images(x_test, y_test, test_dir)

print("Number of benign images in train: " + str(len(os.listdir(os.path.join('train', 'benign')))))
print("Number of malignant images in train: " + str(len(os.listdir(os.path.join('train', 'malignant')))))
print()
print("Number of benign images in test: " + str(len(os.listdir(os.path.join('test', 'benign')))))
print("Number of malignant images in test: " + str(len(os.listdir(os.path.join('test', 'malignant')))))

"""# Data Augmentation

Data Augmentation helps us to diversify the data we feed the training model. We've used the ImageDataGenerator class from Keras for our training directory and applied the following augmentations to our training data such as rotation, flipping, width shift etc.
"""

#listing the augmentations to be applied to training images using ImageDataGenerator
train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    rescale = 1./255,
    brightness_range=[0.3, 0.2],
    horizontal_flip=True,
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    color_mode='rgb',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    shuffle =True,
    seed=42,
)

#using ImageDataGenerator class for test images (only rescaling)
test_datagen = ImageDataGenerator(
    rescale=1./255
)

test_generator = train_datagen.flow_from_directory(
    test_dir,
    color_mode='rgb',
    target_size=(224, 224),
    batch_size=1,
    class_mode=None,
    shuffle =False,
    seed=42,
)

#for visualizing
demo_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.2,
    brightness_range=[0.3, 0.4],
    horizontal_flip=True,
)

os.mkdir('preview')

#for visualizing
x_demo = x_train[0]
x_demo = np.array(x_demo).reshape(1,224, 224, 3)

i = 0
for batch in demo_datagen.flow(x_demo, batch_size=1, save_to_dir='preview', save_prefix='aug_img', save_format='png'):
    i += 1
    if i > 20:
        break

#showing the orignal and augmented images
plt.imshow(x_train[0])
plt.xticks([])
plt.yticks([])
plt.title('Original Image')
plt.show()

plt.figure(figsize=(15,6))
i = 1
for img in os.listdir('preview/'):
    img = cv2.imread('preview/' + img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.subplot(3,7,i)
    plt.imshow(img)
    plt.xticks([])
    plt.yticks([])
    i += 1
    if i > 3*7:
        break
plt.suptitle('Augemented Images')
plt.show()

"""# VGG 16

In classification of our images we've applied the approach of Transfer Learning. We've imported the VGG16 model from Keras and assigned it ImageNet pre-trained weights.
"""

from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

#imported VGG16 with ImageNet weights
VGG_model = VGG16(weights="imagenet", include_top=False, input_shape=(224, 224, 3))

m = Flatten()(VGG_model.output)
m = Dense(128, activation="relu")(m)
m = Dropout(0.5)(m)
output = Dense(1, activation="sigmoid")(m)

model = Model(inputs=VGG_model.input, outputs=output)

model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

model_show = visualkeras.layered_view(model)
plt.axis('off')
plt.imshow(model_show)

model.summary()

model.fit(train_generator, epochs=100)

#predicting
predictions = model.predict(test_generator)

test_labels = test_generator.classes

predictions_bin = (predictions > 0.5)
cf = classification_report(test_labels, predictions_bin)
print(cf)